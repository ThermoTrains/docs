<h3>Stitching</h3>

<ul>
  <li><b>In:</b> Rektifizierte Zug Frames</li>
  <li><b>Out:</b> Zug Panorama</li>
</ul>

<p class="affix">
  Durch die vorgängig angewandten Operationen auf den Frames können wir nun ein vereinfachtes Stitching
  Verfahren anwenden. Die Versuche mit handelsüblichem Panoramastitching brauchbare Resultate zu erzielen,
  schlugen fehl. Die <code>Stitcher</code> Funktionalität von OpenCV bietet zwei Modi an: Landschaftspanorama und Ebenenpanorama.
  Der Landschaftspanorama-Modus geht davon aus, dass die Kamera bei der Aufnahme geschwenkt wurde.
  Der Ebenen-Modus geht davon aus, man hat eine Karte oder Dokumente fotografiert, welche in einer Ebene
  liegen. Das wäre eigentlich unser Anwendungsfall.
</p>

<p>
  Das Hauptproblem besteht darin, dass es jeweils grosse Überlappungen zwischen den einzelnen Frames gibt und
  der Hintergrund immer gleich bleibt. Hinzu kommt, dass sich Wagons ziemlich ähnlich sind. Der erste Versuch
  war einfach mal drauf los zu stitchen. Wir haben sämtliche Frames der <code>Stitcher</code> Klasse übergeben, den
  Modus auf Ebene gestellt und beobachtet was passiert. Es gab einen Fehler, den wir auf keine Weise beheben konnten. Der
  Modus Landschaft hat ein sehr amüsantes Resultat geliefert, das allerdings weniger hilfreich war. Die Wagons waren
  wild übereinandergestapelt und verzerrt.
</p>

<p>
  Der zweite Ansatz war die Bilder gestaffelt zu stitchen. Das heisst wir würden inkrementell ein Bild mit dem
  bisherigen Resultat zusammenstitchen. Das war auch nicht erfolgreich. Man kann auch nicht spezifizieren, wo das
  nächste Bild hinsoll. Also hat OpenCV versucht das Bild irgendwo zu platzieren. Meistens gab es auch hier einen
  Fehler, weil zu wenig Bilder vorhanden waren.
</p>

<p>
  Danach haben wir versucht das Stitching selber zu implementieren mit der OpenCV Methode
  <code>findHomography(...)</code>. Dazu mussten wir Featurepunkte in den beiden Bildern finden, die wir
  zusammenstitchen wollten. Das hat aber auch nicht geklappt. Wahrscheinlich war die Qualität der Featurepunkte
  ungenügend.
</p>

<h4>Pattern Matching</h4>

<p>
  Das Verfahren, das uns dann die Augen geöffnet hat und einwandfrei funktioniert, ist verblüffend simpel. Wir finden in
  zwei aufeinanderfolgenden Frames ein Teilausschnitt von Frame A in Frame B. Dies tun wir mit der <a
  href="#ref-sqdiff-normed">Normalisierten Cross Correlation Funktion</a>. Wenn wir den Teilausschnitt gefunden haben, haben wir eine
  X-Koordinate und dort können wir die Bilder zusammenfügen.
</p>

<figure class="affix">
  <img src="images/post-processing/stitch/template.jpg">
  <figcaption>Template</figcaption>
</figure>
<figure class="affix">
  <img src="images/post-processing/stitch/match.jpg">
  <figcaption>Gefundenes Template</figcaption>
</figure>

<p>
  Fügen wir alle Zugframes zusammen erhalten wir so das gewünschte Resultat.
</p>

<figure class="affix">
  <img src="images/post-processing/stitch/pano.jpg">
  <figcaption>Zug Panorama</figcaption>
</figure>

<figure class="affix">
  <img src="images/post-processing/stitch/pano_ir.jpg">
  <figcaption>Zug Panorama Infrarot</figcaption>
</figure>

<figure class="affix">
  <img src="images/post-processing/stitch/pano_ir_false_color.jpg">
  <figcaption>Zug Panorama Infrarot False Color</figcaption>
</figure>

<p id="ref-sqdiff-normed" class="reference-item">
  <span class="ref">OpenCV: Template Match Modes</span>
  <a href="http://docs.opencv.org/3.2.0/df/dfb/group__imgproc__object.html#ga3a7850640f1fe1f58fe91a2d7583695d"
     target="_blank" rel="noopener">http://docs.opencv.org/3.2.0/df/dfb/group__imgproc__object.html</a>
  <span class="retrieved">15. Juni 2017</span>
</p>
