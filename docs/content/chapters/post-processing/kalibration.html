<h3>Kamerakalibration</h3>

<ul>
  <li><b>In:</b> Schachbrett Frames</li>
  <li><b>Out:</b> JSON Datei mit Kalibrationsdaten</li>
</ul>

<p>
  Die Kalibration der Kamera lösen wir mithilfe eines Schachbretts. Die gut zu detektierenden Eckpunkte zwischen den Kacheln
  sind ein ideales Muster. In der Tat gibt es von OpenCV auch die Methode mit aussagekräftigem Namen
  <code>findChessboardCorners(...)</code>, welche die Eckpunkte findet. Vorgeben muss man die Anzahl Kacheln in Höhe
  sowie Breite.
</p>

<figure>
  <img src="images/post-processing/calibration.jpg">
  <figcaption>Gefundenes Schachbrett Muster</figcaption>
</figure>

<figure>
  <img src="images/post-processing/calibration_ir.jpg">
  <figcaption>Gefundenes Schachbrett Muster Infrarotbild</figcaption>
</figure>

<p>
  Wir brauchen nun viele Testbilder aus verschiedenen Blickwinkeln auf das Schachbrett. Je nachdem ist die Verzerrung
  der Kamera unten, oben, links oder rechts anders. Wir fügen sämtliche gefundenen Punkte in eine Liste ein. Nebenbei
  führen wir eine ideale Liste, in der die Punkte korrekt ausgerichtet sind. Die Methode
  <code>calibrateCamera(...)</code>
  findet dann die Kameramatrix mithilfe der zwei Listen. Weil wir wissen wie gross die Kacheln in Millimeter sind,
  können wir auch die Field of View ausrechnen. Mit unseren FLIR Aufnahmen berechneten wir ein vertikales Sichtfeld von
  33.2° mit einem Fehlerwert (RMS) von 0.64. Der echte Wert wäre eigentlich bei 37° gemäss der FLIR A65 Spezifikation.
</p>

<p>
  Um die Infrarotkamera zu kalibrieren haben wir das ausgedruckte Schachbrettmuster gegen das Sonnenlicht gefilmt.
  So wurden die schwarzen Kacheln aufgewärmt und sind auf dem Bild als weisse Kacheln sichtbar. Das Schachbrettmuster
  ist also invertiert. Der erste Versuch mit einem frisch gedruckten Schachbrett mit noch warmer Tinte, war nicht ausreichend
  genau um die Eckpunkte zu identifizieren.
</p>


<figure>
  <img src="images/post-processing/calibration_window.jpg">
  <figcaption>Schachbrett an warmem Fenster</figcaption>
</figure>

<figure>
  <img src="images/post-processing/chessboard_ir.jpg">
  <figcaption>Schachbrett an warmem Fenster (Infrarot)</figcaption>
</figure>

<p>
  Die gefundenen Daten serialisieren wir in eine JSON Datei.
</p>

<figure>
<pre><code>{
  "cameraMatrix": { "rows": 3, "cols": 3, "type": 6, "data": "..."},
  "distCoeffs": { "rows": 5, "cols": 1, "type": 6, "data": "..."},
  "imageSize": { "width": 1920.0, "height": 1080.0},
  "rvecs": [...]
  "tvecs": [...]
}</code></pre>
  <figcaption>Serialisierte Kalibrationsdaten</figcaption>
</figure>

<p class="affix">
  Der obige Ausschnitt aus der Datei zeigt den Aufbau. Zur Bestimmung des Kameramodells werden die Rotations- und
  Translations-Vektoren jedoch nicht gebraucht. Weil sie jedoch später einmal hilfreich sein könnten, serialisieren wir
  sie trotzdem.
</p>

<h4>Entzerren</h4>

<p>
  Die zuvor serialisierten Daten können wir nun einlesen und die optimale Kameramatrix berechnen. OpenCV bietet dazu
  die Methode <code>getOptimalNewCameraMatrix(...)</code> an, welche die Kameramatrix berechnet. Die einzelnen Frames
  lassen sich dann mit der Methode <code>undistort(...)</code> entzerren. Durch das Entzerren werden jedoch schwarze
  Ränder hinzugefügt. Wir schneiden diese Ränder anschliessend noch ab.
</p>

<figure>
  <img src="images/post-processing/flir_calibration.jpg">
  <figcaption>Rechts: Verzerrt, Links: Entzerrt</figcaption>
</figure>

<figure>
  <img src="images/post-processing/flir_calibration_diff.jpg">
  <figcaption>Absolute Differenz zum entzerrten Bild</figcaption>
</figure>

<p>
  Bei der FLIR Kamera ist die Verzerrung auf die aufgenommenen Distanz von Auge kaum zu erkennen. Nimmt man die absolute
  Differenz der beiden Bilder, kann man den Unterschied aber sichtbar machen.
</p>
